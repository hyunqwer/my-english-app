<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI English Practice (Vercel)</title>
    <!-- ìŠ¤íƒ€ì¼ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ (ìƒëµ) -->
    <style>
        /* ê¸°ì¡´ ìŠ¤íƒ€ì¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© */
        :root { --primary: #10a37f; --bg: #f3f4f6; --card-bg: #ffffff; --error: #ef4444; --success: #22c55e; }
        body { font-family: sans-serif; background: var(--bg); display: flex; justify-content: center; align-items: center; min-height: 100vh; margin: 0; }
        .container { width: 90%; max-width: 600px; background: var(--card-bg); padding: 20px; border-radius: 16px; text-align: center; box-shadow: 0 10px 15px rgba(0,0,0,0.1); }
        .mic-btn { width: 80px; height: 80px; border-radius: 50%; background: var(--primary); border: none; color: white; font-size: 30px; cursor: pointer; margin: 20px; }
        .mic-btn.recording { background: var(--error); animation: pulse 1.5s infinite; }
        .hidden { display: none; }
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(239,68,68,0.7); } 70% { box-shadow: 0 0 0 15px transparent; } }
        /* íƒ­, ë‹¨ì–´ ì¹´ë“œ ë“± ë‚˜ë¨¸ì§€ CSSëŠ” ì´ì „ ì½”ë“œ ì°¸ê³  */
    </style>
</head>
<body>

<div class="container">
    <!-- API Key ì…ë ¥ì°½ ì œê±°ë¨ -->
    
    <!-- íƒ­ ë° UI êµ¬ì¡°ëŠ” ë™ì¼ -->
    <h2 id="q-display">Question 1</h2>
    <div id="content-area">
        <h1 id="main-text">ë‚´ ì´ë¦„ì€ Jadeì•¼</h1>
        <p id="sub-text">ì˜ì–´ë¡œ ë§í•´ë³´ì„¸ìš”.</p>
    </div>

    <div id="feedback" style="min-height: 40px; margin: 10px; color: #666;"></div>

    <button class="mic-btn" id="mic-btn" onclick="toggleRecording()">ğŸ¤</button>
    
    <div>
        <button onclick="prevQuestion()">ì´ì „</button>
        <button onclick="nextQuestion()">ë‹¤ìŒ</button>
    </div>
</div>

<script>
    // --- ë°ì´í„° (ê¸°ì¡´ê³¼ ë™ì¼) ---
    const patternData = [
        { q: "What's your name?", k: "ë‚´ ì´ë¦„ì€ Jadeì•¼", a: "My name is Jade.", s: ["My", "is", "name", "Jade"], hint: "Jade" },
        // ... ë‚˜ë¨¸ì§€ ë°ì´í„° 9ê°œ ...
    ];
    
    let currentIndex = 0;
    let isRecording = false;
    let mediaRecorder;
    let audioChunks = [];

    // --- ë¡œì§ ë³€ê²½ ë¶€ë¶„ ---

    // 1. STT ìš”ì²­ (Vercel Proxyë¡œ ì „ì†¡)
    async function sendToWhisper(blob) {
        const formData = new FormData();
        formData.append("file", blob, "recording.webm");
        formData.append("model", "whisper-1");
        formData.append("language", "en");

        try {
            // ë³€ê²½ëœ URL: /api/proxy?type=stt
            const response = await fetch("/api/proxy?type=stt", {
                method: "POST",
                body: formData // í—¤ë”ëŠ” ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ ì„¤ì • (boundary í¬í•¨)
            });

            if (!response.ok) throw new Error("Server Error");
            const data = await response.json();
            
            document.getElementById('mic-btn').classList.remove('recording');
            processResult(data.text); // ê²°ê³¼ ì²˜ë¦¬ í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼

        } catch (error) {
            alert("ì˜¤ë¥˜: " + error.message);
            document.getElementById('mic-btn').classList.remove('recording');
        }
    }

    // 2. TTS ìš”ì²­ (Vercel Proxyë¡œ ì „ì†¡)
    async function speakQuestion() {
        const text = patternData[currentIndex].q;
        
        try {
            // ë³€ê²½ëœ URL: /api/proxy?type=tts
            const response = await fetch("/api/proxy?type=tts", {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({
                    model: "tts-1",
                    input: text,
                    voice: "alloy"
                })
            });

            const blob = await response.blob();
            const audioUrl = URL.createObjectURL(blob);
            const audio = new Audio(audioUrl);
            audio.play();

        } catch (error) {
            console.error("TTS Error:", error);
        }
    }

    // --- ê¸°ì¡´ ë¡œì§ (ë…¹ìŒ, UI ì—…ë°ì´íŠ¸ ë“±) ---
    // ì´ ë¶€ë¶„ì€ ì´ì „ì— ë“œë¦° ì½”ë“œì˜ toggleRecording, processResult, updateUI ë“±ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.
    // ë‹¨, toggleRecording ë‚´ë¶€ì—ì„œ sendToWhisper í˜¸ì¶œ ì‹œ API Key ì²´í¬ ë¡œì§ì€ ì‚­ì œí•˜ì„¸ìš”.
    
    async function toggleRecording() {
        const btn = document.getElementById('mic-btn');
        if (!isRecording) {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];
            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
            mediaRecorder.onstop = async () => {
                const blob = new Blob(audioChunks, { type: 'audio/webm' });
                document.getElementById('feedback').innerText = "ë¶„ì„ ì¤‘...";
                await sendToWhisper(blob);
            };
            mediaRecorder.start();
            isRecording = true;
            btn.classList.add('recording');
        } else {
            mediaRecorder.stop();
            isRecording = false;
            btn.classList.remove('recording');
        }
    }
    
    function processResult(text) {
        document.getElementById('feedback').innerText = `ì¸ì‹ë¨: "${text}"`;
        // ì •ë‹µ ë¹„êµ ë¡œì§ ìƒëµ (ì´ì „ ì½”ë“œì™€ ë™ì¼)
    }
    
    function nextQuestion() { currentIndex++; updateUI(); }
    function prevQuestion() { if(currentIndex>0) currentIndex--; updateUI(); }
    function updateUI() { 
        document.getElementById('main-text').innerText = patternData[currentIndex].k;
        document.getElementById('q-display').innerText = `Question ${currentIndex+1}`;
    }
    
    window.onload = updateUI;
</script>

</body>
</html>
